
# Book Notes - Psychology of Intel Analysis - Heuer

### Ch1 - Thinking about thinking

```
One key to successful learning is motivation. Some of CIA’s best analysts developed their skills as a consequence of experiencing analytical failure early in their careers. Failure motivated them to be more self-conscious about how they do analysis and to sharpen their thinking process. Tis book aims to help intelligence analysts achieve a higher level of performance. It shows how people make judgments based on incomplete and ambiguous information, and it ofers simple tools and concepts for improving analytical skills
- Pg 2
```

Part 1`: Limitations, Part 2: Tradecraft (Ch 8 most important chapter), Part 3: cognative biases/mental errors via shortcuts, Final chapter: ANalytical checklist`

```
Herbert Simon frst advanced the concept of “bounded” or limited rationality.13 Because of limits in human mental capacity, he argued, the 13. Herbert Simon, Models of Man, 1957. 2 mind cannot cope directly with the complexity of the world. Rather, we construct a simplifed mental model of reality and then work with this model. We behave rationally within the confnes of our mental model, but this model is not always well adapted to the requirements of the real world
Pg 2-3

```


```
Not enough training is focused in this direction—that is, inward toward the analyst’s own thought processes. Training of intelligence ana4 lysts generally means instruction in organizational procedures, methodological techniques, or substantive topics. More training time should be devoted to the mental act of thinking or analyzing. It is simply assumed, incorrectly, that analysts know how to analyze. T
Pg 4-5
```


Mental shortcuts are useful, but w/ new information we may have to unlearn a LOT of baggage

```
Tey are, in essence, a distillation of all that we think we know about a subject. Te problem is how to ensure that the mind remains open to alternative interpretations in a rapidly changing world. Te disadvantage of a mind-set is that it can color and control our perception to the extent that an experienced specialist may be among the last to see what is really happening when events take a new and unexpected turn. When faced with a major paradigm shift, analysts who know the most about a subject have the most to unlearn
Pg 5
```

More data vs Useful/actionable data
```
Te reaction of the Intelligence Community to many problems is to collect more information, even though analysts in many cases already have more information than they can digest. What analysts need is more truly useful information—mostly reliable HUMINT from knowledgeable insiders—to help them make good decisions. Or they need a more accurate mental model and better analytical tools to help them sort through, make sense of, and get the most out of the available ambiguous and conficting information
- Pg 6
```



### Ch 2: Why can't we see what there is to be seen


Beware of Bias
```
As already noted, what people in general and analysts in particular perceive, and how readily they perceive it, are strongly infuenced by their past experience, education, cultural values, and role requirements, as well as by the stimuli recorded by their receptor organs. Many experiments have been conducted to show the extraordinary extent to which the information obtained by an observer depends upon the observer’s own assumptions and preconceptions.
Pg 7
We tend to perceive what we expect to perceive. -8
```

#### We tend to perceive what we expect to perceive. 

We see what we WANT to see vs. we see what we EXPECT to see
```
Tis tendency of people to perceive what they expect to perceive is more important than any tendency to perceive what they want to perceive. In fact, there may be no real tendency toward wishful thinking. Te commonly cited evidence supporting the claim that people tend to perceive what they want to perceive can generally be explained equally well by the expectancy thesis.

Expectations have many diverse sources, including past experience, professional training, and cultural and organizational norms. All these infuences predispose analysts to pay particular attention to certain kinds of information and to organize and interpret this information in certain ways. Perception is also infuenced by the context in which it occurs. Diferent circumstances evoke diferent sets of expectations

Ex: People are more attuned to hearing footsteps behind them when walking in an alley at night than along a city street in daytime, and the meaning attributed to the sound of footsteps will vary under these difering circumstances. A military intelligence analyst may be similarly tuned to perceive indicators of potential confict.
-9
```



On Mindset/though process/bias/worldview/mental shortcuts
```
Patterns of expectations tell analysts, subconsciously, what to look for, what is important, and how to interpret what is seen. Tese patterns form a mind-set that predisposes analysts to think in certain ways. A mind-set is akin to a screen or lens through which one perceives the world.

Actually, mind-sets are neither good nor bad; they are unavoidable. People have no conceivable way of coping with the volume of stimuli that impinge upon their senses, or with the volume and complexity of the data they have to analyze
```

#### Mindsets/Shortcuts are quck to form but resistant to change -10

#### New information is assimilated to existing images. - 11

```
Tis principle explains why gradual, evolutionary change often goes unnoticed. It also explains the phenomenon that an intelligence analyst assigned to work on a topic or country for the frst time may generate accurate insights that have been overlooked by experienced analysts who have worked on the same problem for 10 years. A fresh perspective is sometimes useful; past experience can handicap as well as aid analysis.
```


First perception mover advantage has a hard time getting dislodged
```
Once events have been perceived one way, there is a natural resistance to other perspectives.  Initial exposure to blurred or ambiguous stimuli interferes with accurate perception even after more and better information becomes available.
```

```
Ex: 
Tis efect has been demonstrated experimentally by projecting onto a screen pictures of common, everyday subjects such as a dog standing on grass, a fre hydrant, and an aerial view of a highway cloverleaf intersection.28 Te initial projection was blurred in varying degrees, and the pictures were then brought into focus slowly to determine at what point test subjects could identify them correctly. Tis experiment showed two things. First, those who started viewing the pictures when they were most out of focus had more difculty identifying them when they became clearer than those who started viewing at a less blurred stage. In other words, the greater the initial blur, the clearer the picture had to be before people could recognize it. Second, the longer people were exposed to a blurred picture, the clearer the picture had to be before they could recognize it.
```

Lesson:
```
People form impressions on the basis of very little information, but once formed, they do not reject or change them unless they obtain rather solid evidence. Analysts might seek to limit the adverse impact of this tendency by suspending judgment for as long as possible as new information is being received.
```


- Beware piecemeal analysis, you have to get a systemic whole analysis for better value
	- From the 1973 Israel-Arab War after action report:
	- ```Analysts, according to their own accounts, were often proceeding on the basis of the day’s take, hastily comparing it with material received the previous day. Tey then produced in ‘assembly line fashion’ items which may have refected perceptive intuition but which [did not] accrue from a systematic consideration of an accumulated body of integrated evidence```

- Beware of drawing conclusions too quickly, they might make sense in the moment, but integrate the analysis over time 

From the book:
- Encourage products that clearly delineate their assumptions and chains of inference and that specify the degree and source of uncertainty involved in the conclusions. 
• Support analyses that periodically re-examine key problems from the ground up in order to avoid the pitfalls of the incremental approach. 
• Emphasize procedures that expose and elaborate alternative points of view. 
• Educate consumers about the limitations as well as the capabilities of intelligence analysis; defne a set of realistic expectations as a standard against which to judge analytical performance.



### Ch 3: Memory: How Do We Remember What We Know?

There are 3 primary ways to commit things to memory:
- Rote: AKA: Repetition
- Assimilation: If info fits into a structure/framework already posessed, and usually involves comprehension but requires previous experience
- Mnemonics

Schema: A structure of various points of information/knowledge


### Chapter 4 Strategies for Analytical Judgment: Transcending the Limits of Incomplete Information


Filling in the gaps
```
Judgment is what analysts use to fll gaps in their knowledge. It entails going beyond the available information and is the principal means of coping with uncertainty. It always involves an analytical leap, from the known into the uncertain.
- pg 31
```


Different ways of generating and evaluating hypothesis/conclusions:
- Situation logic: Logic that can be applied to a unique situation that may not apply to broader situations.  Its strenghts are that it's widely applicable and can integrate a large valume of data.  Weaknesses include that if it doesn't take into account other actors' misperceptions or concepts it can lead to faulty conclusions.  Situational knowledge may also be weak in that it may not integrate similar problems (i.e. it is too focused/narrow scope if only attempting to look at one specific situation)

- Applying Theory: Theory is a generalization based on the study of many examples of a similar phenomenon.  This can allow an analyst to focus on key elements of a problem ignoring smaller details and selecting patterns and trends that matter.  But it can be weak in that theory may not provide a timeframe for anticipated developments

- Historical Comparison: This allows for a broad comparison drawing on a wealth of previous data and experience, but one must be careful of making sure that situations are similar enough to draw accurate conclusions.  This is more useful to draw differences than necessarily draw conclusions and can be used to generate good hypothesis.

- Data Immersion: Just looking at the "facts" to try and draw conclusions and checking it against the data, but one should be aware of their biases since data/info cannot speak for itself.  Objectivity can be gained by making assumptions explicit so they can be examined and challenged.

```
Diferent analysts have diferent analytical habits and preferences for analytical strategy. As a broad generalization that admits numerous exceptions, analysts trained in area studies or history tend to prefer situational logic, while those with a strong social science background are more likely to bring theoretical and comparative insights to bear on their work. Te Intelligence Community as a whole is far stronger in situational logic than in theory. In my judgment, intelligence analysts do not generalize enough, as opposed to many academic scholars who generalize too much.

Higher level ofcials who are not experts on the subject at issue use far more theory and comparison and less situational logic than intelligence analysts. Any policymaker or other senior manager who lacks the knowledge base of the specialist and does not have time for detail must, of necessity, deal with broad generalizations. Many decisions must be made, with much less time to consider each of them than is available to the intelligence analyst

-42
```


- The ideal is to generate a set of hypothesis and evaluate each hypothesis to determine the best hypothesis that provides the best fit

Strategies for selecting hypothesis:

```
• "Satisfcing"—selecting the frst identifed alternative that appears "good enough" rather than examining all alternatives to determine which is "best." 

• Incrementalism—focusing on a narrow range of alternatives representing marginal change, without considering the need for dramatic change from an existing position. 

• Consensus—opting for the alternative that will elicit the greatest agreement and support. Simply telling the boss what he or she wants to hear is one version of this. 

• Reasoning by analogy—choosing the alternative that appears most likely to avoid some previous error or to duplicate a previous success. 

• Relying on a set of principles or maxims that distinguish a "good" from a "bad" alternative.

-43
```

- Satisfficing weaknesses: Selective perception/narrow focus on a single hypothesis, failure to generate a complete set of hypothesis, and a focus on evidence that confirms rather than disproves hypothesis.



### Chapter 5 Do You Really Need More Information?

More info vs imperfect info

```
• Once an experienced analyst has the minimum information necessary to make an informed judgment, obtaining additional information generally does not improve the accuracy of his or her estimates. Additional information does, however, lead the analyst to become more confdent in the judgment, to the point of overconfdence. 

• Experienced analysts have an imperfect understanding of what information they actually use in making judgments. Tey are unaware of the extent to which their judgments are determined by a few dominant factors, rather than by the systematic integration of all available information. Analysts actually use much less of the available information than they think they do.

- 52
```



Mental models and associated variables are often flawed

```
s. In short, people’s mental models are simpler than they think, and the analyst is typically unaware not only of which variables should have the greatest infuence, but also which variables actually are having the greatest infuence.
- 55
```

Types of additional info that might be recieved:
- More detail about variables in the analysis
- Additional variables
- Value/weight that should be attributed to the variables
- How variables relate to each other

Data driven analysis: Depends on accuracy and completeness of available data and usually follows logical rules (e.g. evaluating the strength of a unit)
Conceptual driven analysis: Does not have neat boundaries and analysts are out in the wilderness and different analysts may reach different conclusions
Mosaic Theory Analysis: Getting discrete bits of info to try and fit them together like a jigsaw, most analysts don't work this way

- Most analysts work like a medical diagnosis: There's a general picture and the information that comes in either rules out certain diagnoses or strengthens other parts of it

### Chapter 6 Keeping an Open Mind

- Trying to decipher signals from noise is part of the analysts job 

- Part of the job means questioning assumptions by determining how important variables are, validating alternative models/frameworks/approaches, don't fill in gaps by assuming someone else would do the same thing you do, work backwards from the conclusion to the hypothesis, assume that you're wrong, role play and act as a devil's advocate.

- One of the best ways to change your mind is by embracing failure/surprising facts and inquiring into it.  Keep a record of unexpected events and what they might mean, don't just discard them and don't just defer to previaling wisdom check what the facts point to.  


### Chapter 7 Structuring Analytical Problems

Making problems more approachable
```
Te number of possible relationships between variables grows geometrically as the number of variables increases. Tere are two basic tools for dealing with complexity in analysis— decomposition and externalization.

Decomposition means breaking a problem down into its component parts. Tat is, indeed, the essence of analysis

Externalization means getting the decomposed problem out of one’s head and down on paper or on a computer screen in some simplifed form that shows the main variables, parameters, or elements of the problem and how they relate to each other. Writing down the multiplication problem, 46 times 78, is a very simple example of externalizing

- 85
```

Structure the problem

```
Anything that has parts also has a structure that relates these parts to each other. One of the frst steps in doing analysis is to determine an appropriate structure for the analytical problem, so that one can then identify the various parts and begin assembling information on them. Because there are many diferent kinds of analytical problems, there are also many diferent ways to structure analysis. Lists such as Franklin made are one of the simplest structures. An intelligence analyst might make lists of relevant variables, early warning indicators, alternative explanations, possible outcomes, factors a foreign leader will need to take into account when making a decision, or arguments for and against a given explanation or outcome. Other tools for structuring a problem include outlines, tables, diagrams, trees, and matrices, with many sub-species of each. For example, trees include decision trees and fault trees. Diagrams includes causal diagrams, infuence diagrams, fow charts, and cognitive maps. Consideration of all those tools is beyond the scope of this book, but several such tools are discussed. Chapter 11, “Biases in Perception of Cause and Efect,” has a section on Illusory Correlation that uses a (2x2) contingency table to structure analysis of the question: Is deception most likely when the stakes are very high? Chapter 8, “Analysis of Competing Hypotheses,” is arguably the most useful chapter in this book. It recommends using a matrix to array evidence for and against competing hypotheses to explain what is happening now or estimate what may happen in the future.

```


### Chapter 8 Analysis of Competing Hypotheses


The Framework:

```
1. Identify the possible hypotheses to be considered. Use a group of analysts with diferent perspectives to brainstorm the possibilities. 

- Don't limit the number of hypothesis, but understand that things may be categorized as proven, unproven, or disproven

3. Make a list of signifcant evidence and arguments for and against each hypothesis. 

- For each hypothesis, ask yourself this question: If this hypothesis is true, what should I expect to be seeing or not seeing?

- Note the absence of evidence as well as its presence. For example, when weighing the possibility of military attack by an adversary, the steps the adversary has not taken to ready his forces for attack may be more signifcant than the observable steps that have been taken.

4. Prepare a matrix with hypotheses across the top and evidence down the side. Analyze the “diagnosticity” of the evidence and arguments— that is, identify which items are most helpful in judging the relative likelihood of the hypotheses. 

6. Refne the matrix. Reconsider the hypotheses and delete evidence and arguments that have no diagnostic value. 

- In evaluating the relative likelihood of alternative hypotheses, start by looking for evidence or logical deductions that enable you to reject hypotheses, or at least to determine that they are unlikely.
- No matter how much information is consistent with a given hypothesis, one cannot prove that hypothesis is true, because the same information may also be consistent with one or more other hypotheses. On the other hand, a single item of evidence that is inconsistent with a hypothesis may be sufcient grounds for rejecting that hypothesis
- Te matrix should not dictate the conclusion to you. Rather, it should accurately refect your judgment of what is important and how these important factors relate to the probability of each hypothesis. You, not the matrix, must make the decision. Te matrix serves only as an aid to thinking and analysis, to ensure consideration of all the possible interrelationships between evidence and hypotheses and identifcation of those few items that really swing your judgment on the issue.

8. Draw tentative conclusions about the relative likelihood of each hypothesis. Proceed by trying to disprove the hypotheses rather than prove them. 

- When analysis turns out to be wrong, it is often because of key assumptions that went unchallenged and proved invalid. It is a truism that analysts should identify and question assumptions, but this is much easier said than done. Te problem is to determine which assumptions merit questioning.

10. Analyze how sensitive your conclusion is to a few critical items of evidence. Consider the consequences for your analysis if that evidence were wrong, misleading, or subject to a diferent interpretation. 
11. Report conclusions. Discuss the relative likelihood of all the hypotheses, not just the most likely one. 8. Identify milestones for future observation that may indicate events are taking a diferent course than expected.
```


```

Tree key elements distinguish analysis of competing hypotheses from conventional intuitive analysis. • Analysis starts with a full set of alternative possibilities, rather than with a most likely alternative for which the analyst seeks confrmation. Tis ensures that alternative hypotheses receive equal treatment and a fair shake. • Analysis identifes and emphasizes the few items of evidence or assumptions that have the greatest diagnostic value in judging the relative likelihood of the alternative hypotheses. In conventional intuitive analysis, the fact that key evidence may also be consistent with alternative hypotheses is rarely considered explicitly and often ignored. • Analysis of competing hypotheses involves seeking evidence to refute hypotheses. Te most probable hypothesis is usually the one with the least evidence against it, not the one with the most evidence for it. Conventional analysis generally entails looking for evidence to confrm a favored hypothesis.
```

- The power of the system is that it creates a clear way to challenge and question assumptions and creates an audit trail to verify and validate things


### Chapter 9 What Are Cognitive Biases?

- Cognitive biases are mental errors caused by our simplifed information processing strategies. It is important to distinguish cognitive biases from other forms of bias, such as cultural bias, organizational bias, or bias that results from one’s own self-interest. In other words, a cognitive bias does not result from any emotional or intellectual predisposition toward a certain judgment, but rather from subconscious mental procedures for processing information. A cognitive bias is a mental error that is consistent and predictable - 111


### Chapter 10 Biases in Evaluation of Evidence

- We will often bias those closest to us or our own personal experience over statistical aggregate data
- Absence of evidence often leads to "out of sight out of mind" issues, analysts need to call out what variables might be missing or where information might be lacking and update their conclusions based around that
- Oversensitivty to consistency boils down to "its been this way for so long it won't change" or it can be too small of a sample to where large conclusions are drawn from it
- Persistance of impressions even after evidence is discredited, this is usually because with evidence we initially recieve we try and draw causl links w/ it, discrediting the evidence means we have to re-work the mental model we had



### Chapter 11 Biases in Perception of Cause and Effect


- Analysts are often storytellers where coherence and narrative matter along with a frequent bias for causal explanations for order, a central direction/planning/rationality as opposed to accidents, weighing internal/personal factors more heavily than constraints/external factors, overstating the importance of the actor the analyst is working on behalf of, imaging correlation where there is none


### Chapter 12 Biases in Estimating Probabilities

Bias of availability/recall

```
One simplifed rule of thumb commonly used in making probability estimates is known as the availability rule. In this context, “availability” refers to imaginability or retrievability from memory. Psychologists have shown that two cues people use unconsciously in judging the probability of an event are the ease with which they can imagine relevant instances of the event and the number or frequency of such events that they can easily remember
- 147
```


Anchoring

```
Another strategy people seem to use intuitively and unconsciously to simplify the task of making judgments is called anchoring. Some natural starting point, perhaps from a previous analysis of the same subject or from some partial calculation, is used as a frst approximation to the desired judgment. Tis starting point is then adjusted, based on the results of additional information or analysis. Typically, however, the starting point serves as an anchor or drag that reduces the amount of adjustment, so the fnal estimate remains closer to the starting point than it ought to be
```








